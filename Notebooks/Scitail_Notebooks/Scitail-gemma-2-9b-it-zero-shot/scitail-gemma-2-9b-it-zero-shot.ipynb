{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-05T12:32:23.957076Z",
     "iopub.status.busy": "2025-10-05T12:32:23.956836Z",
     "iopub.status.idle": "2025-10-05T12:33:43.153316Z",
     "shell.execute_reply": "2025-10-05T12:33:43.152383Z",
     "shell.execute_reply.started": "2025-10-05T12:32:23.957051Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip install bitsandbytes transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-05T12:42:07.568136Z",
     "iopub.status.busy": "2025-10-05T12:42:07.567485Z",
     "iopub.status.idle": "2025-10-05T12:42:14.878504Z",
     "shell.execute_reply": "2025-10-05T12:42:14.877930Z",
     "shell.execute_reply.started": "2025-10-05T12:42:07.568102Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "path = os.getcwd()\n",
    "while True:\n",
    "    if 'utils.py' in os.listdir(path):\n",
    "        if path not in sys.path:\n",
    "            sys.path.append(path)\n",
    "        break\n",
    "    new_path = os.path.dirname(path)\n",
    "    if new_path == path:\n",
    "        print(\"utils.py not found in any parent folder.\")\n",
    "        break\n",
    "    path = new_path\n",
    "\n",
    "import utils\n",
    "from huggingface_hub import login\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "import re\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-05T12:42:31.071790Z",
     "iopub.status.busy": "2025-10-05T12:42:31.071496Z",
     "iopub.status.idle": "2025-10-05T12:42:31.158958Z",
     "shell.execute_reply": "2025-10-05T12:42:31.158240Z",
     "shell.execute_reply.started": "2025-10-05T12:42:31.071765Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "utils.hf_login(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-05T12:42:31.160013Z",
     "iopub.status.busy": "2025-10-05T12:42:31.159750Z",
     "iopub.status.idle": "2025-10-05T12:42:31.165517Z",
     "shell.execute_reply": "2025-10-05T12:42:31.164891Z",
     "shell.execute_reply.started": "2025-10-05T12:42:31.159987Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-05T12:42:36.283847Z",
     "iopub.status.busy": "2025-10-05T12:42:36.283538Z",
     "iopub.status.idle": "2025-10-05T12:46:25.191042Z",
     "shell.execute_reply": "2025-10-05T12:46:25.190472Z",
     "shell.execute_reply.started": "2025-10-05T12:42:36.283823Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd35d677f25d41b6a3310129b7aa2016",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/47.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f24595a1c44f4d22baa8f81cc21cc4ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbcb41b9353045bcbb77797caecd57bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "655aafb37e7e4071ba1e3a3fd8dbe27a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9894a50975d0494dbc497a020a4c68eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/857 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-05 12:42:45.087226: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1759668165.294189      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1759668165.350013      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97506bdec9444d0b80cd55a03828ca9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/39.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83b685ce22a84f3cb70f6ff153b7858d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6579080ce167468fbd290809ae42bbe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.90G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f3575341f5d43e0a0eb6f202871e9fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36e3603f720e43a0bf75c3c8baea0b9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/3.67G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c70d2cbb4955489185efad278342412c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35eefde65c024830bc11ec1d397b43bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f5f1e14b4054bf08023c55f52d37728",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/173 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = 'google/gemma-2-9b-it'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=quantization_config,\n",
    "    attn_implementation=\"eager\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-05T12:50:26.750596Z",
     "iopub.status.busy": "2025-10-05T12:50:26.749910Z",
     "iopub.status.idle": "2025-10-05T12:50:26.869945Z",
     "shell.execute_reply": "2025-10-05T12:50:26.869344Z",
     "shell.execute_reply.started": "2025-10-05T12:50:26.750571Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "scitail_test = pd.read_csv('/kaggle/input/scitail-test/scitail_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-05T12:50:31.284696Z",
     "iopub.status.busy": "2025-10-05T12:50:31.283866Z",
     "iopub.status.idle": "2025-10-05T12:50:31.310663Z",
     "shell.execute_reply": "2025-10-05T12:50:31.309808Z",
     "shell.execute_reply.started": "2025-10-05T12:50:31.284664Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2126 entries, 0 to 2125\n",
      "Data columns (total 4 columns):\n",
      " #   Column                      Non-Null Count  Dtype \n",
      "---  ------                      --------------  ----- \n",
      " 0   premise                     2126 non-null   object\n",
      " 1   hypothesis                  2126 non-null   object\n",
      " 2   label                       2126 non-null   object\n",
      " 3   hypothesis_graph_structure  2126 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 66.6+ KB\n"
     ]
    }
   ],
   "source": [
    "scitail_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-05T12:50:37.502184Z",
     "iopub.status.busy": "2025-10-05T12:50:37.501667Z",
     "iopub.status.idle": "2025-10-05T12:50:37.520544Z",
     "shell.execute_reply": "2025-10-05T12:50:37.520004Z",
     "shell.execute_reply.started": "2025-10-05T12:50:37.502162Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "      <th>hypothesis_graph_structure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Based on the list provided of the uses of subs...</td>\n",
       "      <td>If a substance has a ph value greater than 7,t...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>a substance&lt;&gt;has&lt;&gt;a ph value greater than 7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If one or two            base pairs are change...</td>\n",
       "      <td>Invertebrates (and higher animals) can also be...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Invertebrates (and higher animals&lt;&gt;can be plac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>At high temperatures, the solid dye converts i...</td>\n",
       "      <td>Gases and liquids become solids at low tempera...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Gases and liquids&lt;&gt;become&lt;&gt;solids</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chapter 11 Gas and Kinetic Theory .</td>\n",
       "      <td>The behavior of ideal gases is explained by ki...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>The behavior of ideal gases&lt;&gt;is explained&lt;&gt;by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Both the continental crust and the oceanic cru...</td>\n",
       "      <td>Gabbro is a dark dense rock that can be found ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Gabbro&lt;&gt;is&lt;&gt;a dark dense rock that can be foun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             premise  \\\n",
       "0  Based on the list provided of the uses of subs...   \n",
       "1  If one or two            base pairs are change...   \n",
       "2  At high temperatures, the solid dye converts i...   \n",
       "3                Chapter 11 Gas and Kinetic Theory .   \n",
       "4  Both the continental crust and the oceanic cru...   \n",
       "\n",
       "                                          hypothesis    label  \\\n",
       "0  If a substance has a ph value greater than 7,t...  neutral   \n",
       "1  Invertebrates (and higher animals) can also be...  neutral   \n",
       "2  Gases and liquids become solids at low tempera...  neutral   \n",
       "3  The behavior of ideal gases is explained by ki...  neutral   \n",
       "4  Gabbro is a dark dense rock that can be found ...  neutral   \n",
       "\n",
       "                          hypothesis_graph_structure  \n",
       "0        a substance<>has<>a ph value greater than 7  \n",
       "1  Invertebrates (and higher animals<>can be plac...  \n",
       "2                  Gases and liquids<>become<>solids  \n",
       "3  The behavior of ideal gases<>is explained<>by ...  \n",
       "4  Gabbro<>is<>a dark dense rock that can be foun...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scitail_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-05T12:50:41.988942Z",
     "iopub.status.busy": "2025-10-05T12:50:41.988347Z",
     "iopub.status.idle": "2025-10-05T12:50:41.993612Z",
     "shell.execute_reply": "2025-10-05T12:50:41.992839Z",
     "shell.execute_reply.started": "2025-10-05T12:50:41.988916Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Find the max_length for tokenization to avoid wasting computing.\n",
    "utils.find_max_length(scitail_test, tokenizer=tokenizer, dataset_type='scitail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset and create a dataloader.\n",
    "dataset_test = utils.MyDataset(dataframe=scitail_test,\n",
    "                               tokenizer=tokenizer,\n",
    "                               dataset_type='scitail',\n",
    "                               prompt_max_length=,\n",
    "                               label_max_length=)\n",
    "\n",
    "dataloader = DataLoader(dataset_test, batch_size=16, shuffle=False) # Change batch size according to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-05T12:52:18.614838Z",
     "iopub.status.busy": "2025-10-05T12:52:18.614326Z",
     "iopub.status.idle": "2025-10-05T12:52:25.274927Z",
     "shell.execute_reply": "2025-10-05T12:52:25.274144Z",
     "shell.execute_reply.started": "2025-10-05T12:52:18.614814Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral\n",
      "neutral\n",
      "neutral\n",
      "entailment\n"
     ]
    }
   ],
   "source": [
    "# Test run\n",
    "utils.test_run(model=model, dataloader=dataloader, tokenizer=tokenizer, dataset_type='scitail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create checkpoint\n",
    "checkpoint_dir = \"/kaggle/working\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "print(\"Checkpoint directory:\", checkpoint_dir)\n",
    "\n",
    "checkpoint_path = os.path.join(\n",
    "    checkpoint_dir,\n",
    "    f\"checkpoint_scitail_{model_id.split('/')[1]}.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "checkpoint_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Load checkpoint if it exists\n",
    "if os.path.exists(checkpoint_path):\n",
    "    predicted_labels, gold_labels, no_answer, start_batch = utils.load_checkpoint()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(tqdm(dataloader, desc=\"Evaluating\", unit=\"batch\")):\n",
    "        # Continue from last checkpoint\n",
    "        if i < start_batch:\n",
    "            continue\n",
    "\n",
    "        input_ids_batch = batch[\"input_ids\"].to(model.device) # Move to GPU\n",
    "        attention_mask_batch = batch[\"attention_mask\"].to(model.device) # Move to GPU\n",
    "        gold_labels_batch = batch[\"labels\"] # Keep to CPU\n",
    "\n",
    "        # Get outputs\n",
    "        outputs = model.generate(input_ids=input_ids_batch, attention_mask=attention_mask_batch, max_new_tokens=6)\n",
    "        outputs_decoded = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "        predicted_labels_batch = utils.get_predictions(outputs_decoded=outputs_decoded, no_answer=no_answer, dataset_type='scitail')\n",
    "        predicted_labels.extend(predicted_labels_batch)\n",
    "        gold_labels.extend(gold_labels_batch)\n",
    "\n",
    "        # Save checkpoint\n",
    "        if i % 50 == 0 or i == len(dataloader) - 1:\n",
    "            torch.save({\"predicted_labels\": predicted_labels,\n",
    "                        \"gold_labels\": gold_labels,\n",
    "                        \"no_answer\": no_answer,\n",
    "                        \"batch_no\": i+1}, checkpoint_path)\n",
    "\n",
    "            print(f\"Checkpoint saved: {i+1}, {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load(checkpoint_path)\n",
    "predicted_labels = checkpoint[\"predicted_labels\"]\n",
    "gold_labels = checkpoint[\"gold_labels\"]\n",
    "no_answer = checkpoint[\"no_answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Calculate accuracy score\n",
    "accuracy = accuracy_score(gold_labels, predicted_labels)\n",
    "print(f\"Accuracy: {accuracy:.4f}, no answers: {no_answer}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8408251,
     "sourceId": 13268380,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
